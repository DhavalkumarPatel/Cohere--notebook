{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install cohere\n",
    "\n",
    "# Import the required modules\n",
    "import cohere\n",
    "\n",
    "# Set up the Cohere client\n",
    "api_key = 'doLqjOzGKiQxEmEyb2PhMeYa6qmVwfATPOyex606' # Paste your API key here. Remember to not share it publicly \n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets from huggingface\n",
    "from datasets import list_datasets, load_dataset\n",
    "\n",
    "#Load other libraries, modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset financial_phrasebank/sentences_allagree to C:/Users/dhava/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb9380855f64acfab60eaee41930401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset financial_phrasebank downloaded and prepared to C:/Users/dhava/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3a0c4e9f694e87a9509c9250a52133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('financial_phrasebank', 'sentences_allagree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data\n",
    "X = dataset['train']['sentence']\n",
    "y = dataset['train']['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi-label dataset\n",
    "y.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Shape:  (680,)\n"
     ]
    }
   ],
   "source": [
    "#checking shapes\n",
    "print('Test Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "Cohere provides three options to for text classification:\n",
    "1. Few-shot classification with the Classify endpoint\n",
    "2. Develop custom classifeier with the Embed endpoint\n",
    "3. Model Finetuning\n",
    "\n",
    "The details could be found from the following link: https://txt.cohere.ai/classify-three-options/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Classify Endpoint\n",
    "\n",
    "Reference: https://docs.cohere.ai/reference/classify\n",
    "\n",
    "To make a prediction, Classify uses the provided examples of text + label pairs as a reference. \n",
    "\n",
    "The dataset pairs (i.e., text, label) are called EXAMPLES. They provide context to the model.\n",
    "\n",
    "**co.Classify** module has three main arguments: model_type, inputs (texts to be classified), examples (context)\n",
    "\n",
    "If using a custom model, then examples are not required. In this case, as we are interested in classifying sentiment on a financial dataset, I will be using 'finance-sentiment' model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#to use examples, apply the following lines of code.\\nfrom cohere.classify import Example\\n\\n#create examples\\nexamples = list()\\nfor txt, lbl in zip(X_train.tolist(),y_train.tolist()):\\n    examples.append(Example(txt,lbl))\\n    \\n#change the model type to 'medium' or as per requirement\\n\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#to use examples, apply the following lines of code.\n",
    "from cohere.classify import Example\n",
    "\n",
    "#create examples\n",
    "examples = list()\n",
    "for txt, lbl in zip(X_train.tolist(),y_train.tolist()):\n",
    "    examples.append(Example(txt,lbl))\n",
    "    \n",
    "#change the model type to 'medium' or as per requirement\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification\n",
    "def classify_text(text,examples):\n",
    "    classifications = co.classify(\n",
    "        model='finance-sentiment',\n",
    "        inputs=[text]\n",
    "        )\n",
    "    \n",
    "    return classifications.classifications[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification predictions on the test dataset\n",
    "\n",
    "y_pred = list()\n",
    "\n",
    "for i in range(int(len(X_test)%100)+1):\n",
    "    time.sleep(60)\n",
    "    y_pred.extend(X_test[i*100:i*100+100].apply(classify_text, args=(examples,)).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.50\n",
      "F1-score: 97.48\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "y_test_c = [\"NEGATIVE\" if b==0 else \"POSITIVE\" if b==2 else \"NEUTRAL\"for b in y_test]\n",
    "\n",
    "accuracy = accuracy_score(y_test_c, y_pred)\n",
    "f1 = f1_score(y_test_c, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {100*accuracy:.2f}')\n",
    "print(f'F1-score: {100*f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "The results are extremely promising!!!\n",
    "\n",
    "It would be interesting to analyse the text where we have misclassifications. Of the 680 samples in the test set, 97.50 were correctly classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mis_classes = [j for i,j in zip(y_pred,y_test_c) if i!=j]\n",
    "\n",
    "mis_index = [i for i in range(len(y_test)) if y_test_c[i]!=y_pred[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_df = pd.DataFrame()\n",
    "mis_df['text'] = np.array(X_test.tolist())[mis_index]\n",
    "mis_df['original_label'] = np.array(y_test_c)[mis_index]\n",
    "mis_df['predicted_label'] = np.array(y_pred)[mis_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>original_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Profitability ( EBIT % ) was 13.6 % , compared...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finnish business software group AffectoGenimap...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negotiations with representatives of the perso...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Net profit was 35.5 mln compared with 29.8 mln .</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Markets had been expecting a poor performance ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The company also said that in Poland a profita...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>According to CEO Matti Perkonoja of the parent...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Operating profit was EUR 1.6 mn in 2005 compar...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>During the strike , Finnair estimates to incur...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The refining margin for the year was $ 13.39 -...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The currency effect had a 3.0 pct , or 20 mln ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neste oil 's board proposed 1.00 eur dividend ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Typically , the transmission power level can b...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Finnish energy company Fortum Oyj said on Nove...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pretax loss totalled EUR 49.9 mn , compared to...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Net cash flow from operating activities was a ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TELE2 Affarsvarlden gave a `` buy '' recommend...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text original_label  \\\n",
       "0   Profitability ( EBIT % ) was 13.6 % , compared...       NEGATIVE   \n",
       "1   Finnish business software group AffectoGenimap...       NEGATIVE   \n",
       "2   Negotiations with representatives of the perso...        NEUTRAL   \n",
       "3    Net profit was 35.5 mln compared with 29.8 mln .       POSITIVE   \n",
       "4   Markets had been expecting a poor performance ...       POSITIVE   \n",
       "5   The company also said that in Poland a profita...       POSITIVE   \n",
       "6   According to CEO Matti Perkonoja of the parent...       NEGATIVE   \n",
       "7   Operating profit was EUR 1.6 mn in 2005 compar...       NEGATIVE   \n",
       "8   During the strike , Finnair estimates to incur...       NEGATIVE   \n",
       "9   The refining margin for the year was $ 13.39 -...       POSITIVE   \n",
       "10  The currency effect had a 3.0 pct , or 20 mln ...       NEGATIVE   \n",
       "11  Neste oil 's board proposed 1.00 eur dividend ...       POSITIVE   \n",
       "12  Typically , the transmission power level can b...        NEUTRAL   \n",
       "13  Finnish energy company Fortum Oyj said on Nove...       POSITIVE   \n",
       "14  Pretax loss totalled EUR 49.9 mn , compared to...       NEGATIVE   \n",
       "15  Net cash flow from operating activities was a ...       NEGATIVE   \n",
       "16  TELE2 Affarsvarlden gave a `` buy '' recommend...       POSITIVE   \n",
       "\n",
       "   predicted_label  \n",
       "0         POSITIVE  \n",
       "1         POSITIVE  \n",
       "2         NEGATIVE  \n",
       "3          NEUTRAL  \n",
       "4          NEUTRAL  \n",
       "5          NEUTRAL  \n",
       "6          NEUTRAL  \n",
       "7         POSITIVE  \n",
       "8          NEUTRAL  \n",
       "9          NEUTRAL  \n",
       "10         NEUTRAL  \n",
       "11         NEUTRAL  \n",
       "12        NEGATIVE  \n",
       "13         NEUTRAL  \n",
       "14        POSITIVE  \n",
       "15        POSITIVE  \n",
       "16         NEUTRAL  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for the misclassified text in the test set/\n",
    "mis_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
